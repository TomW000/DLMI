{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torchview import draw_graph\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(utils.Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.images, self.labels = [], []\n",
    "\n",
    "        with h5py.File(file, 'r') as dataset:\n",
    "            for key in dataset.keys():\n",
    "                self.images.append(dataset[key+'/img'][:])\n",
    "                self.labels.append(dataset[key+'/label'][()])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "        \n",
    "def init_model(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.PLIP = model = CLIPModel.from_pretrained(\"vinid/plip\")\n",
    "        self.processor = CLIPProcessor.from_pretrained(\"vinid/plip\")\n",
    "        self.vision_model = CLIPModel.from_pretrained(\"vinid/plip\").vision_model\n",
    "        for parameter in self.vision_model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.Linear(768, 384), nn.ReLU(),\n",
    "                                        nn.Linear(384, 192), nn.ReLU(),\n",
    "                                        nn.Linear(192, 48), nn.ReLU(),\n",
    "                                        nn.Linear(48,2))\n",
    "        self.apply(init_model)\n",
    "            \n",
    "    def forward(self, image):\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\", padding=True, do_rescale = False)\n",
    "        with torch.no_grad():\n",
    "            embedding = self.vision_model(pixel_values=inputs['pixel_values']).last_hidden_state[:, 0, :]\n",
    "        return self.classifier(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size, val_batch_size, test_batch_size = 100, 100, 100\n",
    "train_set = utils.DataLoader(CustomDataset('train.h5') , batch_size = train_batch_size, shuffle = True)\n",
    "validation_set = utils.DataLoader(CustomDataset('val.h5') , batch_size = val_batch_size, shuffle = True)\n",
    "test_set = utils.DataLoader(CustomDataset('test.h5') , batch_size = test_batch_size, shuffle = True)\n",
    "model = Model()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use(epochs):\n",
    "    train_accs, val_accs, test_accs = [], [], []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = 0, 0\n",
    "        for image, label in train_set:\n",
    "                model.train()\n",
    "                y_pred = model(image)\n",
    "                loss = loss_fn(y_pred, label)\n",
    "                train_loss += loss.item()\n",
    "                train_acc += (torch.argmax(y_pred) == label).sum().item()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        train_loss /= len(train_set*train_batch_size)\n",
    "        train_acc = train_acc/(len(train_set*train_batch_size))*100\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Testing loop\n",
    "        test_loss, test_acc = 0, 0\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for image, label in test_set:\n",
    "                    test_pred = model(image)  \n",
    "                    testloss = loss_fn(test_pred, label)\n",
    "                    test_loss += testloss.item()\n",
    "                    test_acc += (torch.argmax(test_pred) == label).sum().item()\n",
    "            \n",
    "        test_loss /= len(test_set*test_batch_size) \n",
    "        test_acc = test_acc/(len(train_set*train_batch_size))*100\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        if (test_acc == 100) and (train_acc==100):\n",
    "            last_epoch=epoch+1\n",
    "            print(f\"Optimum reached at epoch {last_epoch}\")\n",
    "            break\n",
    "        last_epoch=epochs\n",
    "    plt.figure(figsize=(5,5))\n",
    "    i = range(1,last_epoch+1)\n",
    "    plt.plot(i, train_accs, color = 'blue', label='Train accuracy')\n",
    "    plt.plot(i, test_accs, color = 'green', label='Test accuracy')\n",
    "    plt.gca().set_ylim([0, 110])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
