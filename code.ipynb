{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import tqdm \n",
    "import torch.utils.data as utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"#'/kaggle/input/mva-dlmi-2025-histopathology-ood-classification/'\n",
    "TRAIN_IMAGES_PATH = path + 'train.h5'\n",
    "VAL_IMAGES_PATH = path + 'val.h5'\n",
    "TEST_IMAGES_PATH = path + 'test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    'mps' if torch.backends.mps.is_available() and torch.backends.mps.is_built() \n",
    "    else 'cuda' if torch.cuda.is_available() \n",
    "    else 'cpu'\n",
    ")\n",
    "scaler = torch.cuda.amp.GradScaler('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(utils.Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.pixel_values = []\n",
    "        self.labels = [] if file != TEST_IMAGES_PATH else None\n",
    "        self.processor = CLIPProcessor.from_pretrained(\"vinid/plip\")\n",
    "\n",
    "        with h5py.File(file, 'r') as dataset:\n",
    "            for key in dataset.keys():\n",
    "                image = dataset[key+'/img'][:]\n",
    "                inputs = self.processor(\n",
    "                    images=image,\n",
    "                    return_tensors=\"pt\",\n",
    "                    do_rescale=False,\n",
    "                    padding=True\n",
    "                )\n",
    "                self.pixel_values.append(inputs[\"pixel_values\"].squeeze(0)) \n",
    "                \n",
    "                if file != TEST_IMAGES_PATH:\n",
    "                    label = dataset[key+'/label'][()]\n",
    "                    self.labels.append(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pixel_values) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None: \n",
    "            return self.pixel_values[idx], torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return self.pixel_values[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = device \n",
    "        \n",
    "        self.vision_model = CLIPModel.from_pretrained(\"vinid/plip\").vision_model\n",
    "        \n",
    "        for param in self.vision_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vision_model.to(self.device)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 384), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(384, 192), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(192, 48), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.apply(init_model)\n",
    "        self.to(self.device)\n",
    "            \n",
    "    def forward(self, pixel_values):\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedding = self.vision_model(pixel_values=pixel_values).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        return self.classifier(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size, val_batch_size, test_batch_size = 1000, 680, 850\n",
    "\n",
    "train_dataset = CustomDataset(TRAIN_IMAGES_PATH)\n",
    "val_dataset = CustomDataset(VAL_IMAGES_PATH)\n",
    "test_dataset = CustomDataset(TEST_IMAGES_PATH)\n",
    "\n",
    "train_loader = utils.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = utils.DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = utils.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, labels):\n",
    "    binary_preds = (predictions >= 0.5).float()\n",
    "    correct = (binary_preds == labels).float()\n",
    "    accuracy = correct.mean() * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use(epochs):\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epochs), desc='Epochs'):\n",
    "        model.train()\n",
    "        total_acc = 0.0\n",
    "        \n",
    "        for images, labels in tqdm.tqdm(train_loader, desc=f'Train {epoch+1}', leave=True):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            with torch.cuda.amp.autocast('cuda'):\n",
    "\n",
    "                y_pred = model(images).squeeze()\n",
    "                loss = loss_fn(y_pred, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, labels)\n",
    "            total_acc += acc\n",
    "\n",
    "        train_acc = total_acc / (len(train_loader))\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        total_val_acc = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm.tqdm(val_loader, desc=f'Val {epoch+1}', leave=True):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                with torch.cuda.amp.autocast('cuda'):\n",
    "                    val_pred = model(images).squeeze()\n",
    "                \n",
    "                val_acc = calculate_accuracy(val_pred, labels)\n",
    "                total_val_acc += val_acc\n",
    "\n",
    "        val_acc = total_val_acc / len(val_loader)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch{epoch+1}/{epochs} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "    test_predictions = []\n",
    "    \n",
    "    with h5py.File(TEST_IMAGES_PATH, 'r') as f:\n",
    "        idx = list(f.keys())\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in tqdm.tqdm(test_loader, desc='Testing'):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            with torch.cuda.amp.autocast('cuda'):\n",
    "                test_pred = (model(images).squeeze() > 0.5).float()\n",
    "            test_predictions.append(test_pred)\n",
    "            \n",
    "        test = list(torch.cat(test_predictions).cpu().numpy())\n",
    "\n",
    "    return list(zip(idx, test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = use(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=['ID', 'Pred'])\n",
    "df.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
